{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanushax21/AI-bootcamp/blob/main/YOLOv8_Bootcamp%2C_Ivan_Shvalev%2C_1673633.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "# AI Bootcamp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "611bf785-b8e0-4368-b2ab-17cde88477ac"
      },
      "source": [
        "%pip install ultralytics\n",
        "%pip install roboflow\n",
        "import ultralytics\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.4/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLOv8 Predict Docs](https://docs.ultralytics.com/modes/train/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5108d093-3327-42c1-8f38-8880258c3b80"
      },
      "source": [
        "# Run inference on an image with YOLOv8n\n",
        "!yolo predict model=yolov8s.pt source='https://ultralytics.com/images/zidane.jpg'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100% 21.5M/21.5M [00:00<00:00, 150MB/s] \n",
            "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
            "100% 165k/165k [00:00<00:00, 6.76MB/s]\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 2 ties, 116.6ms\n",
            "Speed: 2.0ms preprocess, 116.6ms inference, 641.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or you can run inference directly on an online image.\n",
        "!yolo predict model=yolov8n.pt source='https://media.wired.com/photos/593256b42a990b06268a9e21/master/w_2240,c_limit/traffic-jam-getty.jpg'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWjqI5RzIIQ7",
        "outputId": "bfc711a7-2a94-42c7-e329-c35ed4901265"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 83.1MB/s]\n",
            "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Downloading https://media.wired.com/photos/593256b42a990b06268a9e21/master/w_2240,c_limit/traffic-jam-getty.jpg to 'traffic-jam-getty.jpg'...\n",
            "100% 231k/231k [00:00<00:00, 9.65MB/s]\n",
            "image 1/1 /content/traffic-jam-getty.jpg: 448x640 65 cars, 1 bus, 124.2ms\n",
            "Speed: 3.9ms preprocess, 124.2ms inference, 476.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset preparation\n",
        "\n",
        "Dataset made on the roboflow will put in this part"
      ],
      "metadata": {
        "id": "4k4cRUGyI_Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "roboflow_url = \"https://app.roboflow.com/ds/Ly2aHFW9Jd?key=zJ6m1PgCB1\"\n",
        "!curl -L $roboflow_url > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "# You should make sure to have a validation set. If you don't have one you can copy your train set.\n",
        "!cp -r train/. valid/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwYkDo1MI-8B",
        "outputId": "1928768f-732a-441e-b01b-fcdc43271bc3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   894  100   894    0     0    958      0 --:--:-- --:--:-- --:--:--   959\n",
            "100 40.5M  100 40.5M    0     0  27.9M      0  0:00:01  0:00:01 --:--:-- 90.4M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: data.yaml               \n",
            "   creating: test/\n",
            "   creating: test/images/\n",
            " extracting: test/images/MicrosoftTeams-image-35-_png.rf.deff1ae914f02a6f8730163ae7565e0b.jpg  \n",
            " extracting: test/images/MicrosoftTeams-image-39-_png.rf.3cc72525313b54d628be284cae8e04ec.jpg  \n",
            " extracting: test/images/MicrosoftTeams-image-5-_png.rf.d22a9d8ecba2af05474f53686526afba.jpg  \n",
            "   creating: test/labels/\n",
            " extracting: test/labels/MicrosoftTeams-image-35-_png.rf.deff1ae914f02a6f8730163ae7565e0b.txt  \n",
            " extracting: test/labels/MicrosoftTeams-image-39-_png.rf.3cc72525313b54d628be284cae8e04ec.txt  \n",
            " extracting: test/labels/MicrosoftTeams-image-5-_png.rf.d22a9d8ecba2af05474f53686526afba.txt  \n",
            "   creating: train/\n",
            "   creating: train/images/\n",
            " extracting: train/images/MicrosoftTeams-image-1-_png.rf.950919b226253221aad560abc4e20dc6.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-11-_png.rf.4d3aa340b74ad406ea9c8b317360672b.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-12-_png.rf.ccb116b9ca278d7a1c98b04aeadf3c1c.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-14-_png.rf.abd194133e390060407dd7852e18a16b.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-15-_png.rf.d5d8b9b2718379e750c10b3f074d7e70.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-17-_png.rf.a8bd5508ca3a844be51bbe0e025fd345.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-18-_png.rf.c240ae0f1a2063f02f19081b6558ab4b.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-2-_png.rf.a503b17e8a8bafa3af8910eed38b6118.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-20-_png.rf.e5815799764f116908ddd203a14fc229.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-21-_png.rf.8317d0838324e4c9b858f0785bd0b291.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-22-_png.rf.26e2caf4f8182dfe0298577f267a0188.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-23-_png.rf.b5254a322fb5de66462bd26d8258d718.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-25-_png.rf.6e60c07b30c461dca6b9336f2a8d0bfb.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-26-_png.rf.2641bf19a8f7e3b393552a2350865795.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-27-_png.rf.0a702f983f5afccdb2e5503f010c804f.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-28-_png.rf.ac42b0371590822d1ef82121bdd32ccc.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-29-_png.rf.f5a91eeed75f2ffc930e0b200c61d536.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-3-_png.rf.c279183f8c92b8a4ee83c92749bbc236.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-30-_png.rf.0604ee3ba38f265f87d37aabe7a6d5a4.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-31-_png.rf.cd70ce2e1d8e889284e0f3be1c74c99a.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-33-_png.rf.caec28ffb3d66d5a8b91f0464f652023.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-34-_png.rf.6384eb8351a98e67893fe8695d75da4d.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-36-_png.rf.58eb0a8965b4229033f664e23dedaccb.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-4-_png.rf.07aca622fe17ad61fe8a0d5fc43c9107.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-41-_png.rf.74c7281aafd895617dce9673f4d1765a.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image-6-_png.rf.8e166f4fa8363be15b21039720fad6dd.jpg  \n",
            " extracting: train/images/MicrosoftTeams-image_png.rf.27c98f470000d2082a7e1ec751c62904.jpg  \n",
            "   creating: train/labels/\n",
            " extracting: train/labels/MicrosoftTeams-image-1-_png.rf.950919b226253221aad560abc4e20dc6.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-11-_png.rf.4d3aa340b74ad406ea9c8b317360672b.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-12-_png.rf.ccb116b9ca278d7a1c98b04aeadf3c1c.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-14-_png.rf.abd194133e390060407dd7852e18a16b.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-15-_png.rf.d5d8b9b2718379e750c10b3f074d7e70.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-17-_png.rf.a8bd5508ca3a844be51bbe0e025fd345.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-18-_png.rf.c240ae0f1a2063f02f19081b6558ab4b.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-2-_png.rf.a503b17e8a8bafa3af8910eed38b6118.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-20-_png.rf.e5815799764f116908ddd203a14fc229.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-21-_png.rf.8317d0838324e4c9b858f0785bd0b291.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-22-_png.rf.26e2caf4f8182dfe0298577f267a0188.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-23-_png.rf.b5254a322fb5de66462bd26d8258d718.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-25-_png.rf.6e60c07b30c461dca6b9336f2a8d0bfb.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-26-_png.rf.2641bf19a8f7e3b393552a2350865795.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-27-_png.rf.0a702f983f5afccdb2e5503f010c804f.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-28-_png.rf.ac42b0371590822d1ef82121bdd32ccc.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-29-_png.rf.f5a91eeed75f2ffc930e0b200c61d536.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-3-_png.rf.c279183f8c92b8a4ee83c92749bbc236.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-30-_png.rf.0604ee3ba38f265f87d37aabe7a6d5a4.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-31-_png.rf.cd70ce2e1d8e889284e0f3be1c74c99a.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-33-_png.rf.caec28ffb3d66d5a8b91f0464f652023.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-34-_png.rf.6384eb8351a98e67893fe8695d75da4d.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-36-_png.rf.58eb0a8965b4229033f664e23dedaccb.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-4-_png.rf.07aca622fe17ad61fe8a0d5fc43c9107.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-41-_png.rf.74c7281aafd895617dce9673f4d1765a.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image-6-_png.rf.8e166f4fa8363be15b21039720fad6dd.txt  \n",
            " extracting: train/labels/MicrosoftTeams-image_png.rf.27c98f470000d2082a7e1ec751c62904.txt  \n",
            "   creating: valid/\n",
            "   creating: valid/images/\n",
            " extracting: valid/images/MicrosoftTeams-image-13-_png.rf.428cf3bca510fe7421553a5a1f65e9e1.jpg  \n",
            " extracting: valid/images/MicrosoftTeams-image-19-_png.rf.61347c2f19667ab9b5fb3cdac0562d8e.jpg  \n",
            " extracting: valid/images/MicrosoftTeams-image-32-_png.rf.f53cadd6bd66112a8629fd59931f9309.jpg  \n",
            " extracting: valid/images/MicrosoftTeams-image-37-_png.rf.ac303eb550b73ad987b1384bd79311a4.jpg  \n",
            " extracting: valid/images/MicrosoftTeams-image-38-_png.rf.2b2b12f70e1de56bf66f680eb73f0b44.jpg  \n",
            " extracting: valid/images/MicrosoftTeams-image-42-_png.rf.45789acc6980b3ccc9c9150e80b06363.jpg  \n",
            " extracting: valid/images/MicrosoftTeams-image-7-_png.rf.a2048a264b5abb2f4982452d8cec9a17.jpg  \n",
            " extracting: valid/images/MicrosoftTeams-image-8-_png.rf.7cb53319dd6bd7f6583352e45dea94e6.jpg  \n",
            "   creating: valid/labels/\n",
            " extracting: valid/labels/MicrosoftTeams-image-13-_png.rf.428cf3bca510fe7421553a5a1f65e9e1.txt  \n",
            " extracting: valid/labels/MicrosoftTeams-image-19-_png.rf.61347c2f19667ab9b5fb3cdac0562d8e.txt  \n",
            " extracting: valid/labels/MicrosoftTeams-image-32-_png.rf.f53cadd6bd66112a8629fd59931f9309.txt  \n",
            " extracting: valid/labels/MicrosoftTeams-image-37-_png.rf.ac303eb550b73ad987b1384bd79311a4.txt  \n",
            " extracting: valid/labels/MicrosoftTeams-image-38-_png.rf.2b2b12f70e1de56bf66f680eb73f0b44.txt  \n",
            " extracting: valid/labels/MicrosoftTeams-image-42-_png.rf.45789acc6980b3ccc9c9150e80b06363.txt  \n",
            " extracting: valid/labels/MicrosoftTeams-image-7-_png.rf.a2048a264b5abb2f4982452d8cec9a17.txt  \n",
            " extracting: valid/labels/MicrosoftTeams-image-8-_png.rf.7cb53319dd6bd7f6583352e45dea94e6.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "YOLOv8 model is trained on the given dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16833e90-c224-4007-b8a3-2f70006ed742"
      },
      "source": [
        "# Train YOLOv8n on COCO8 for 4 epochs\n",
        "!yolo train model=yolov8s.pt data=data.yaml epochs=15 imgsz=640"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 18.0MB/s]\n",
            "2023-12-18 14:18:10.398258: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-18 14:18:10.398314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-18 14:18:10.399592: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels... 27 images, 0 backgrounds, 0 corrupt: 100% 27/27 [00:00<00:00, 1178.94it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels... 35 images, 0 backgrounds, 0 corrupt: 100% 35/35 [00:00<00:00, 1085.92it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/15      4.09G      1.382      3.631      1.293         51        640: 100% 2/2 [00:03<00:00,  1.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:03<00:00,  1.50s/it]\n",
            "                   all         35         68      0.269      0.453      0.257      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/15      4.04G      1.393      3.496      1.316         63        640: 100% 2/2 [00:00<00:00,  3.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.93it/s]\n",
            "                   all         35         68      0.261      0.442      0.246      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/15      4.04G      1.454      3.738       1.38         42        640: 100% 2/2 [00:00<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.09it/s]\n",
            "                   all         35         68      0.236      0.324      0.218      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/15       4.1G      1.216      2.902      1.255         44        640: 100% 2/2 [00:00<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.72it/s]\n",
            "                   all         35         68       0.48      0.805      0.649      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/15      4.14G      1.054       1.77       1.09         46        640: 100% 2/2 [00:00<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.35it/s]\n",
            "                   all         35         68      0.701       0.82      0.689      0.502\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/15      4.12G      1.096      2.957       1.16         11        640: 100% 2/2 [00:04<00:00,  2.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:02<00:00,  1.05s/it]\n",
            "                   all         35         68      0.785      0.786      0.775      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/15      4.12G     0.9582      1.921      1.043         20        640: 100% 2/2 [00:00<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.06it/s]\n",
            "                   all         35         68      0.664      0.932      0.853      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/15      4.12G     0.8979      1.626      1.022         21        640: 100% 2/2 [00:00<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.10it/s]\n",
            "                   all         35         68      0.727       0.92      0.894      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/15      4.12G     0.9254      1.731      1.089         36        640: 100% 2/2 [00:00<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:02<00:00,  1.17s/it]\n",
            "                   all         35         68      0.833      0.871      0.874      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/15      4.12G      0.821      1.441     0.9959         17        640: 100% 2/2 [00:00<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:02<00:00,  1.00s/it]\n",
            "                   all         35         68      0.832      0.828      0.883       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/15      4.12G      0.823      1.355     0.9859         16        640: 100% 2/2 [00:00<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.04it/s]\n",
            "                   all         35         68        0.9      0.782      0.909       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/15      4.12G     0.8528      1.154      1.013         23        640: 100% 2/2 [00:00<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:02<00:00,  1.35s/it]\n",
            "                   all         35         68      0.767       0.93       0.93      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/15      4.12G     0.8761      1.147     0.9696         26        640: 100% 2/2 [00:00<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.27it/s]\n",
            "                   all         35         68       0.83      0.933       0.95      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/15      4.14G     0.8023      1.169      0.916         21        640: 100% 2/2 [00:00<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.31it/s]\n",
            "                   all         35         68      0.856       0.94      0.962      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/15      4.12G     0.8091      1.105     0.9479         19        640: 100% 2/2 [00:00<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:04<00:00,  2.28s/it]\n",
            "                   all         35         68      0.827      0.969      0.967      0.726\n",
            "\n",
            "15 epochs completed in 0.021 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.227 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.91it/s]\n",
            "                   all         35         68      0.827      0.968      0.967      0.725\n",
            "                Normal         35         35      0.793          1      0.963      0.766\n",
            "                 Wrong         35         33      0.861      0.937      0.971      0.684\n",
            "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on custom images\n",
        "In this part, it is possible to see how the model works on images and how well it recognizes them"
      ],
      "metadata": {
        "id": "ye0xIy4_L5ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "traindirs = os.listdir(\"/content/runs/detect/\")\n",
        "traindirs = sorted(traindirs)\n",
        "# Get the weights from the last training run\n",
        "traindir = traindirs[-1]\n",
        "print(traindir)\n",
        "\n",
        "model = YOLO(f\"/content/runs/detect/{traindir}/weights/last.pt\")\n",
        "results = model.predict(source=\"/content/train/images\", show=False, save=True) # Display preds. Accepts all YOLO predict arguments"
      ],
      "metadata": {
        "id": "DRwyS52lLvUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99628657-63e1-4b19-cdfa-75aedf333e30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\n",
            "WARNING âš ï¸ NMS time limit 0.550s exceeded\n",
            "image 1/27 /content/train/images/MicrosoftTeams-image-1-_png.rf.950919b226253221aad560abc4e20dc6.jpg: 640x480 1 Wrong, 74.4ms\n",
            "image 2/27 /content/train/images/MicrosoftTeams-image-11-_png.rf.4d3aa340b74ad406ea9c8b317360672b.jpg: 640x480 1 Normal, 1 Wrong, 12.1ms\n",
            "image 3/27 /content/train/images/MicrosoftTeams-image-12-_png.rf.ccb116b9ca278d7a1c98b04aeadf3c1c.jpg: 640x480 1 Normal, 1 Wrong, 12.1ms\n",
            "image 4/27 /content/train/images/MicrosoftTeams-image-14-_png.rf.abd194133e390060407dd7852e18a16b.jpg: 640x480 1 Wrong, 12.1ms\n",
            "image 5/27 /content/train/images/MicrosoftTeams-image-15-_png.rf.d5d8b9b2718379e750c10b3f074d7e70.jpg: 640x480 1 Normal, 12.1ms\n",
            "image 6/27 /content/train/images/MicrosoftTeams-image-17-_png.rf.a8bd5508ca3a844be51bbe0e025fd345.jpg: 640x480 1 Normal, 1 Wrong, 12.1ms\n",
            "image 7/27 /content/train/images/MicrosoftTeams-image-18-_png.rf.c240ae0f1a2063f02f19081b6558ab4b.jpg: 640x480 1 Normal, 12.1ms\n",
            "image 8/27 /content/train/images/MicrosoftTeams-image-2-_png.rf.a503b17e8a8bafa3af8910eed38b6118.jpg: 640x480 2 Wrongs, 12.1ms\n",
            "image 9/27 /content/train/images/MicrosoftTeams-image-20-_png.rf.e5815799764f116908ddd203a14fc229.jpg: 640x480 1 Wrong, 12.1ms\n",
            "image 10/27 /content/train/images/MicrosoftTeams-image-21-_png.rf.8317d0838324e4c9b858f0785bd0b291.jpg: 640x480 1 Normal, 12.1ms\n",
            "image 11/27 /content/train/images/MicrosoftTeams-image-22-_png.rf.26e2caf4f8182dfe0298577f267a0188.jpg: 640x480 1 Normal, 12.1ms\n",
            "image 12/27 /content/train/images/MicrosoftTeams-image-23-_png.rf.b5254a322fb5de66462bd26d8258d718.jpg: 640x480 1 Normal, 12.1ms\n",
            "image 13/27 /content/train/images/MicrosoftTeams-image-25-_png.rf.6e60c07b30c461dca6b9336f2a8d0bfb.jpg: 640x480 4 Wrongs, 12.2ms\n",
            "image 14/27 /content/train/images/MicrosoftTeams-image-26-_png.rf.2641bf19a8f7e3b393552a2350865795.jpg: 640x480 1 Normal, 12.2ms\n",
            "image 15/27 /content/train/images/MicrosoftTeams-image-27-_png.rf.0a702f983f5afccdb2e5503f010c804f.jpg: 640x480 1 Normal, 12.2ms\n",
            "image 16/27 /content/train/images/MicrosoftTeams-image-28-_png.rf.ac42b0371590822d1ef82121bdd32ccc.jpg: 640x480 5 Normals, 1 Wrong, 12.1ms\n",
            "image 17/27 /content/train/images/MicrosoftTeams-image-29-_png.rf.f5a91eeed75f2ffc930e0b200c61d536.jpg: 640x480 5 Normals, 2 Wrongs, 12.1ms\n",
            "image 18/27 /content/train/images/MicrosoftTeams-image-3-_png.rf.c279183f8c92b8a4ee83c92749bbc236.jpg: 640x480 1 Wrong, 12.2ms\n",
            "image 19/27 /content/train/images/MicrosoftTeams-image-30-_png.rf.0604ee3ba38f265f87d37aabe7a6d5a4.jpg: 640x480 1 Normal, 12.2ms\n",
            "image 20/27 /content/train/images/MicrosoftTeams-image-31-_png.rf.cd70ce2e1d8e889284e0f3be1c74c99a.jpg: 640x480 4 Wrongs, 12.2ms\n",
            "image 21/27 /content/train/images/MicrosoftTeams-image-33-_png.rf.caec28ffb3d66d5a8b91f0464f652023.jpg: 640x480 4 Normals, 1 Wrong, 12.8ms\n",
            "image 22/27 /content/train/images/MicrosoftTeams-image-34-_png.rf.6384eb8351a98e67893fe8695d75da4d.jpg: 640x480 5 Normals, 2 Wrongs, 12.1ms\n",
            "image 23/27 /content/train/images/MicrosoftTeams-image-36-_png.rf.58eb0a8965b4229033f664e23dedaccb.jpg: 640x480 5 Normals, 12.1ms\n",
            "image 24/27 /content/train/images/MicrosoftTeams-image-4-_png.rf.07aca622fe17ad61fe8a0d5fc43c9107.jpg: 640x480 1 Wrong, 12.1ms\n",
            "image 25/27 /content/train/images/MicrosoftTeams-image-41-_png.rf.74c7281aafd895617dce9673f4d1765a.jpg: 480x640 1 Normal, 1 Wrong, 64.1ms\n",
            "image 26/27 /content/train/images/MicrosoftTeams-image-6-_png.rf.8e166f4fa8363be15b21039720fad6dd.jpg: 640x480 (no detections), 12.8ms\n",
            "image 27/27 /content/train/images/MicrosoftTeams-image_png.rf.27c98f470000d2082a7e1ec751c62904.jpg: 640x480 2 Wrongs, 12.1ms\n",
            "Speed: 3.2ms preprocess, 16.4ms inference, 24.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}